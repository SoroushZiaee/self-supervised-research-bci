{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27acfbd7-4ea1-4e80-b835-859ad8f7fcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "%load_ext autoreload\n",
    "# %reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813a5816-f9c4-4fe7-8716-a9d096dd7593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b774357a-1c12-4ea0-8712-99095c43ce54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a081a2c-c75d-492c-8ec5-291111fda027",
   "metadata": {},
   "source": [
    "## Model implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ecc2d8-c172-4020-9f57-90717d322e2b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Generating synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b445d9ad-cb5d-44cc-8f0c-d12a926f3231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal, norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9236ef-385d-4224-aef7-78061bc0c6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of class 1\n",
    "# from: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.multivariate_normal.html\n",
    "rv1 = multivariate_normal([4, 2], [[2.0, 0], [0, 2.0]])\n",
    "\n",
    "x, y = np.mgrid[-6:6:.01, -5:5:.01]\n",
    "pos = np.dstack((x, y))\n",
    "\n",
    "fig2 = plt.figure()\n",
    "ax2 = fig2.add_subplot(111)\n",
    "ax2.contourf(x, y, rv1.pdf(pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650b5a7e-f76c-49f1-a1f4-3e584fa851b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of class 2\n",
    "rv2 = multivariate_normal([-4, -2], [[2.0, 0], [0, 2.0]])\n",
    "\n",
    "x, y = np.mgrid[-6:6:.01, -5:5:.01]\n",
    "pos = np.dstack((x, y))\n",
    "\n",
    "fig2 = plt.figure()\n",
    "ax2 = fig2.add_subplot(111)\n",
    "ax2.contourf(x, y, rv2.pdf(pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603c0974-86c2-4663-be91-318dd9b19796",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_electrode_positions = {\n",
    "    # row 1\n",
    "    \"Nz\": (0, 5),\n",
    "    # row 2\n",
    "    \"Fp1\": (-1 ,4), \"Fpz\": (0, 4), \"Fp2\": (1, 4),\n",
    "    # row 3\n",
    "    \"AF7\": (-2, 3), \"AF3\": (-1, 3), \"AFz\": (0, 3), \"AF4\": (1, 3), \"AF8\": (2, 3),\n",
    "    # row 4\n",
    "    \"F9\": (-5, 2), \"F7\": (-4, 2), \"F5\": (-3 ,2), \"F3\": (-2, 2), \"F1\": (-1, 2), \"Fz\": (0, 2),\n",
    "    \"F2\": (1, 2), \"F4\": (2, 2), \"F6\": (3, 2), \"F8\": (4, 2), \"F10\": (5, 2),\n",
    "    # row 5\n",
    "    \"FT9\": (-5, 1), \"FT7\": (-4, 1), \"FC5\": (-3 ,1), \"FC3\": (-2, 1), \"FC1\": (-1, 1), \"FCz\": (0, 1),\n",
    "    \"FC2\": (1, 1), \"FC4\": (2, 1), \"FC6\": (3, 1), \"FC8\": (4, 1), \"FC10\": (5, 1),\n",
    "    # row 6\n",
    "    \"A1\": (-6, 0), \"T9\": (-5, 0), \"T7\": (-4, 0), \"C5\": (-3, 0), \"C3\": (-2, 0), \"C1\": (-1, 0), \"Cz\": (0, 0), \n",
    "    \"C2\": (1, 0), \"C4\": (2, 0), \"C6\": (3, 0), \"T8\": (4, 0), \"T10\": (5, 0), \"A2\": (6, 0), \n",
    "    # row 7\n",
    "    \"TP9\": (-5, -1), \"TP7\": (-4, -1), \"CP5\": (-3, -1), \"CP3\": (-2, -1), \"CP1\": (-1, -1), \"CPz\": (0, -1), \n",
    "    \"CP2\": (1, -1), \"CP4\": (2, -1), \"CP6\": (3, -1), \"TP8\": (4, -1), \"TP10\": (5, -1), \n",
    "    # row 8\n",
    "    \"P9\": (-5, -2), \"P7\": (-4, -2), \"P5\": (-3, -2), \"P3\": (-2, -2), \"P1\": (-1, -2), \"Pz\": (0, -2), \n",
    "    \"P2\": (1, -2), \"P4\": (2, -2), \"P6\": (3, -2), \"P8\": (4, -2), \"P10\": (5, -2),\n",
    "    # row 9\n",
    "    \"PO7\": (-2, -3), \"PO3\": (-1, -3), \"POz\": (0, -3), \"PO4\": (1, -3), \"PO8\": (2, -3), \n",
    "    # row 10\n",
    "    \"O1\": (-1, -4), \"Oz\": (0, -4), \"O2\": (1, -4), \n",
    "    # row 11\n",
    "    \"Iz\": (0, -5), \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98de4fe7-c37f-4ec4-8ae8-c1a6de2308b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating 100 samples from class 1\n",
    "eeg_data = {key: [] for key in eeg_electrode_positions.keys()}\n",
    "labels = []\n",
    "for i in range(10):\n",
    "    # Generating 1 sec recording\n",
    "    for key, value in eeg_electrode_positions.items():\n",
    "        eeg_data[key].append(np.abs(np.random.normal(rv1.pdf(value), 0.01, 256)))\n",
    "    labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4056e277-3292-406e-8d73-b018c6a75e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating another 100 samples from class 2\n",
    "for i in range(10):\n",
    "    # Generating 1 sec recording\n",
    "    for key, value in eeg_electrode_positions.items():\n",
    "        eeg_data[key].append(np.abs(np.random.normal(rv2.pdf(value), 0.01, 256)))\n",
    "    labels.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eae0b1c-cce8-4dca-a2c4-dd8dd3bb47e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in eeg_electrode_positions.items():\n",
    "    eeg_data[key] = np.expand_dims(np.array(eeg_data[key]), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8ca3a6-cfc1-4ea4-b797-d20224f92a49",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Modeules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e6311f-de82-44c5-880b-625ca111ef9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "del sys.modules[\"pase_eeg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b643e329-331e-4b6b-b0cd-436b63dee7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from pase_eeg.nn.modules import SincBlock, ResBlock\n",
    "\n",
    "from torch import Tensor\n",
    "from typing import Type, Any, Callable, Union, List, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252b5900-a7a2-4d91-8cb1-289cd108d4a8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Channels-wise frequency domain feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bde06da-cf2e-4aeb-8e3d-9ecd0f870e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveFe(nn.Module):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        channel_positions,\n",
    "        out_shape,\n",
    "        name=\"WaveFe\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.channel_positions = channel_positions\n",
    "        self.out_shape = out_shape\n",
    "        \n",
    "        self.sinc = SincBlock(in_channels=1,\n",
    "                              out_channels=64,\n",
    "                              kernel_size=5,\n",
    "                              stride=1,\n",
    "                              padding=\"valid\",\n",
    "                              activation=\"prelu\",\n",
    "                              norm_type=\"bnorm\",\n",
    "                              sr=256,\n",
    "                             )\n",
    "        self.blocks = nn.ModuleList()\n",
    "        self.blocks.append(ResBlock(in_channels=64,\n",
    "                          out_channels=64,\n",
    "                          kernel_size=3,\n",
    "                          padding=\"valid\",\n",
    "                          dilations=[1, 2],\n",
    "                          activation=\"prelu\",\n",
    "                          norm_type=\"bnorm\",\n",
    "                        ))\n",
    "        \n",
    "        self.blocks.append(ResBlock(in_channels=64,\n",
    "                          hidden_channels=64,\n",
    "                          out_channels=1,\n",
    "                          kernel_size=3,\n",
    "                          padding=\"valid\",\n",
    "                          dilations=[1, 2],\n",
    "                          activation=\"prelu\",\n",
    "                          norm_type=\"bnorm\",\n",
    "                        ))\n",
    "\n",
    "    def forward(self, batch_dict, device=None, mode=None):\n",
    "        values = list(batch_dict.values())\n",
    "        batch_size = values[0].size()[0]\n",
    "        x = torch.vstack(values)\n",
    "        \n",
    "        x = self._forward_feature_extractor(x)\n",
    "        \n",
    "        x = self._flatten_by_position_2d(x, batch_size)\n",
    "                                         \n",
    "        return x\n",
    "    \n",
    "    def _forward_feature_extractor(self, x):\n",
    "        x = self.sinc(x)\n",
    "        # print(x.size())\n",
    "        \n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "            # print(x.size())\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def _flatten_by_position_2d(self, x, batch_size):\n",
    "        res = torch.zeros((batch_size, *self.out_shape, x.size()[-1]), device=x.device)\n",
    "        for i, value in enumerate(self.channel_positions.values()):\n",
    "            idx = self._position_to_index(value, self.out_shape)\n",
    "            res[:, idx[0], idx[1], :] = x[i*batch_size:(i+1)*batch_size, :, :].squeeze()\n",
    "\n",
    "            \n",
    "        return res\n",
    "            \n",
    "    def _position_to_index(self, position, shape):\n",
    "\n",
    "    \n",
    "        center = (shape[0] // 2, shape[1] // 2)\n",
    "        index = (center[0] - position[1], center[1] + position[0])\n",
    "        return index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fd1a94-3424-4dd5-b075-0dce421e6cad",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### spacial domain feature extractor with classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0617193-1d43-4283-a8f4-52e26401ded2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion: int = 1\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes: int,\n",
    "        planes: int,\n",
    "        stride: int = 1,\n",
    "        groups: int = 1,\n",
    "        base_width: int = 64,\n",
    "        dilation: int = 1,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "        dropout: float = None,\n",
    "    ) -> None:\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            inplanes,\n",
    "            planes,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            padding=dilation,\n",
    "            groups=groups,\n",
    "            bias=False,\n",
    "            dilation=dilation,\n",
    "        )\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        if dropout is not None:\n",
    "            self.dropout1 = nn.Dropout2d(p=dropout)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            planes,\n",
    "            planes,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=dilation,\n",
    "            groups=groups,\n",
    "            bias=False,\n",
    "            dilation=dilation,\n",
    "        )\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        if dropout is not None:\n",
    "            self.dropout2 = nn.Dropout2d(p=dropout)\n",
    "        # self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        if self.dropout is not None:\n",
    "            out = self.dropout1(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        # if self.downsample is not None:\n",
    "        #     identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        if self.dropout is not None:\n",
    "            out = self.dropout2(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fb1b14-13eb-4427-b846-36866308b268",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockCls2d(nn.Module):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        num_classes: int,\n",
    "        name=\"EEG-Classifier\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.num_classes = num_classes\n",
    "        self.inplanes = 64\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels, self.inplanes, kernel_size=1, stride=1, padding=0, bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.blocks = nn.ModuleList()\n",
    "        self.blocks.append(BasicBlock(inplanes=self.inplanes,\n",
    "                          planes=self.inplanes,\n",
    "                          stride=1,\n",
    "                          base_width=64,\n",
    "                          dilation=1,\n",
    "                          dropout=0.2,\n",
    "                        ))\n",
    "        \n",
    "        self.blocks.append(BasicBlock(inplanes=self.inplanes,\n",
    "                          planes=self.inplanes,\n",
    "                          stride=1,\n",
    "                          base_width=64,\n",
    "                          dilation=1,\n",
    "                          dropout=0.2,\n",
    "                        ))\n",
    "        \n",
    "        self.conv_cls = nn.Conv2d(\n",
    "            self.inplanes, self.num_classes, kernel_size=1, stride=1, padding=0, bias=False\n",
    "        )\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(self.num_classes, self.num_classes)\n",
    "\n",
    "    def forward(self, x, device=None, mode=None):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "            \n",
    "        x = self.conv_cls(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5754a56d-0838-4788-9172-e14c339afe56",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16fcce6-5051-4b3d-a9ed-7524f3bea320",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGCls(nn.Module):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        channel_positions,\n",
    "        channels_plane_shape=(11, 13),\n",
    "        num_classes = 2,\n",
    "        name=\"EEG-Classifier\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.channel_positions = channel_positions\n",
    "        self.channels_plane_shape = channels_plane_shape\n",
    "        \n",
    "        self.signal_block = WaveFe(channel_positions=self.channel_positions,\n",
    "               out_shape=self.channels_plane_shape)\n",
    "        self.spacial_block = BlockCls2d(in_channels=252, num_classes=num_classes)\n",
    "        \n",
    "    def forward(self, batch_dict, device=None, mode=None):\n",
    "        x = self.signal_block(batch_dict, device=device)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        x = self.spacial_block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2b66da-ac59-48c6-8bed-311397793b25",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Module Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bffa3b-db8b-46ee-9393-230e45d5d7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device_str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device_str = \"cpu\"\n",
    "device = torch.device(device_str)\n",
    "print(\"Torch Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f703b2f-434b-41aa-a4dd-dd13babaa448",
   "metadata": {},
   "source": [
    "#### Signal Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d1742c-1444-42ee-8b11-43d57a198a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = {}\n",
    "for key, value in eeg_electrode_positions.items():\n",
    "    batch[key] = torch.Tensor(eeg_data[key])[10:18, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faf1e12-cf8d-4115-8c6b-f00a28c5e432",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"P7\"].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd4de50-0d94-45ed-b9de-dd7d358453f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = WaveFe(channel_positions=eeg_electrode_positions,\n",
    "               out_shape=(11, 13)).to()\n",
    "out = model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28479452-2d38-43f8-a103-6ec23f2b3bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c947675-28a0-4ce1-bebf-5a1402741158",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = out.detach().cpu().numpy().mean(-1).mean(0)\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6b8c55-4038-480f-a700-c03c4204c781",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = {}\n",
    "for key, value in eeg_electrode_positions.items():\n",
    "    batch[key] = torch.Tensor(eeg_data[key])[0:8, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08dd9ab-6968-4f23-9222-202371871c66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = WaveFe(channel_positions=eeg_electrode_positions,\n",
    "               out_shape=(11, 13)).to()\n",
    "out = model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890408cb-e1aa-4589-bf01-fd1c06c98e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = out.detach().cpu().numpy().mean(-1).mean(0)\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9841de-b691-4796-84be-4290ee70d4fc",
   "metadata": {},
   "source": [
    "#### Spacial Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32024366-4699-4920-9ea1-7617da305f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EEGCls(channel_positions=eeg_electrode_positions,\n",
    "        channels_plane_shape=(11, 13),\n",
    "        num_classes = 2)\n",
    "out = model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e644c8-4733-4181-abe5-82ffad24dbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715451db-48d2-4fcd-b17c-7a0454ab223d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train/Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfb7a14-4f04-4e69-b77e-dd4258bc1249",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fffb0e1-f846-4aad-a291-33ac80df5afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b052fe48-a7f2-45a6-b814-d5fb78285654",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGSyntheticDataset(Dataset):\n",
    "    \"\"\" \"\"\"\n",
    "\n",
    "    def __init__(self, data=None, transforms=None):\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        if data is None:\n",
    "            # distribution of class 1\n",
    "            # from: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.multivariate_normal.html\n",
    "            rv1 = multivariate_normal([4, 2], [[2.0, 0], [0, 2.0]])\n",
    "            x, y = np.mgrid[-6:6:.01, -5:5:.01]\n",
    "            pos = np.dstack((x, y))\n",
    "\n",
    "            # distribution of class 2\n",
    "            rv2 = multivariate_normal([-4, -2], [[2.0, 0], [0, 2.0]])\n",
    "            x, y = np.mgrid[-6:6:.01, -5:5:.01]\n",
    "            pos = np.dstack((x, y))\n",
    "\n",
    "            # Generating 100 samples from class 1\n",
    "            self.eeg_data = {key: [] for key in eeg_electrode_positions.keys()}\n",
    "            self.labels = []\n",
    "            for i in range(100):\n",
    "                # Generating 1 sec recording\n",
    "                for key, value in eeg_electrode_positions.items():\n",
    "                    self.eeg_data[key].append(np.abs(np.random.normal(rv1.pdf(value), 0.01, 256)))\n",
    "                self.labels.append(1)\n",
    "\n",
    "            # Generating another 100 samples from class 2\n",
    "            for i in range(100):\n",
    "                # Generating 1 sec recording\n",
    "                for key, value in eeg_electrode_positions.items():\n",
    "                    self.eeg_data[key].append(np.abs(np.random.normal(rv2.pdf(value), 0.01, 256)))\n",
    "                self.labels.append(2)\n",
    "\n",
    "            for key, value in eeg_electrode_positions.items():\n",
    "                self.eeg_data[key] = np.expand_dims(np.array(self.eeg_data[key]), 1)\n",
    "            self.labels = np.array(self.labels)\n",
    "        else:\n",
    "            self.eeg_data = data[0]\n",
    "            self.labels = data[1]\n",
    "\n",
    "        self.classes = [1, 2]\n",
    "        self.cls_idx_map = {1: 0, 2: 1}\n",
    "\n",
    "        self.indices = list(range(len(self.labels)))\n",
    "\n",
    "    def class_to_index(self, cls):\n",
    "        return self.cls_idx_map[cls]\n",
    "\n",
    "    def index_to_class(self, index):\n",
    "        return self.classes[index]\n",
    "\n",
    "    def get_class(self, index):\n",
    "        return self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        wav = {key: self.eeg_data[key][idx, :, :] for key in self.eeg_data.keys()}\n",
    "        \n",
    "        label = self.get_class(idx)\n",
    "        label = self.class_to_index(label)\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            wav, label = self.transforms(wav, label)\n",
    "\n",
    "        return wav, label\n",
    "\n",
    "    def subset(self, indices):\n",
    "        data = {}\n",
    "        for key, value in self.eeg_data.items():\n",
    "                data[key] = self.eeg_data[key][indices, :, :]\n",
    "        return self.__class__((data, self.labels[indices]), transforms=self.transforms)\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        imgs = {key: torch.vstack([item[0][key].unsqueeze(0) for item in batch]) for key in batch[0][0].keys()}\n",
    "        trgts = torch.vstack([item[1] for item in batch]).squeeze()\n",
    "\n",
    "        return [imgs, trgts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452b6799-1966-4c92-844e-b00b0900c9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    def __init__(self, device):\n",
    "        self.device = device\n",
    "        \n",
    "    def __call__(self, data, label):\n",
    "        for key in data.keys():\n",
    "            data[key] = torch.tensor(data[key]).float().to(self.device)\n",
    "        label = torch.tensor([label], dtype=torch.long).to(self.device)\n",
    "            \n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a101bd-e24b-4bc3-97b4-49ce62273f0a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Lightning Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f369326-dffe-4baf-8ade-305bb0a53a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4279c1-5fee-41c3-a257-2485c2a74746",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "\n",
    "class LitEEG(LightningModule):\n",
    "    def __init__(self, learning_rate=3e-4):\n",
    "\n",
    "        super().__init__()\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.model = EEGCls(channel_positions=eeg_electrode_positions,\n",
    "        channels_plane_shape=(11, 13),\n",
    "        num_classes = 2)\n",
    "        \n",
    "        self.accuracy = Accuracy()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x, device=self.device)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.accuracy(preds, y)\n",
    "        \n",
    "        \n",
    "        # Calling self.log will surface up scalars for you in TensorBoard\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        self.log(\"train_acc\", self.accuracy, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.accuracy(preds, y)\n",
    "\n",
    "        # Calling self.log will surface up scalars for you in TensorBoard\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", self.accuracy, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # Here we just reuse the validation_step for testing\n",
    "        return self.validation_step(batch, batch_idx)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_epoch_end(self, training_step_outputs):\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    def training_epoch_start(self, training_step_outputs):\n",
    "        print(\"\\n\")\n",
    "    #     print(f\"\\nAccuracy : {self.accuracy.compute()}\\n\")\n",
    "\n",
    "    ####################\n",
    "    # DATA RELATED HOOKS\n",
    "    ####################\n",
    "    def setup(self, stage=None):\n",
    "        self.dataset = EEGSyntheticDataset(transforms=\n",
    "                        ToTensor(device = \n",
    "                                 torch.device(\"cuda:0\")))\n",
    "        self.train_idx, self.test_idx, _, _ = train_test_split(\n",
    "            list(range(len(self.dataset))),\n",
    "            self.dataset.labels,\n",
    "            stratify=self.dataset.labels,\n",
    "            test_size=0.2,\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.dataset.subset(self.train_idx), batch_size=BATCH_SIZE,\n",
    "                          collate_fn=self.dataset.collate_fn)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.dataset.subset(self.test_idx), batch_size=BATCH_SIZE,\n",
    "                          collate_fn=self.dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9763de9-e674-445e-8231-e9ce66fccdf6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b525d2a-7072-48b8-8eee-54772c5eddc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init our model\n",
    "model = LitEEG()\n",
    "\n",
    "# Initialize a trainer\n",
    "trainer = Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=4,\n",
    ")\n",
    "\n",
    "# Train the model âš¡\n",
    "trainer.fit(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
